import numpy as np
import keras
from keras import backend as K
from keras.layers import GaussianNoise,GaussianDropout
from keras.models import Sequential
from keras.layers.core import Dense, Flatten
from keras.layers import Conv2D, MaxPooling2D, Activation, Concatenate, AveragePooling2D, Dropout
from keras.optimizers import Adam, SGD, Adadelta, RMSprop, Nadam
from keras.metrics import categorical_crossentropy, mean_squared_error
from keras.preprocessing.image import ImageDataGenerator
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import *
from keras.layers import Input
from keras.models import Model
from keras.layers.advanced_activations import LeakyReLU
import matplotlib.pyplot as plt
import cv2
from keras.callbacks import EarlyStopping, ModelCheckpoint

path = '/home/rishab/IIT_M_Internship/ASL/asl_alphabet_train'
v_path = '/home/rishab/IIT_M_Internship/ASL/asl_alphabet_valid'
t_path = '/home/rishab/IIT_M_Internship/ASL/asl_alphabet_test'

batches = ImageDataGenerator().flow_from_directory(path, target_size=(448,448), classes=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','space','T','U','V','W','X','Y','Z'], shuffle=True, batch_size=64)
v_batches = ImageDataGenerator().flow_from_directory(v_path, target_size=(448,448), classes=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','space','T','U','V','W','X','Y','Z'], shuffle=True, batch_size=64)
t_batches = ImageDataGenerator().flow_from_directory(t_path, target_size=(448,448), classes=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','space','T','U','V','W','X','Y','Z'], shuffle=True, batch_size=120)
t_imgs,t_labels = next(t_batches)

img_input = Input(shape=(448,448,3))
#image = GaussianNoise(35)(img_input)
image = BatchNormalization()(img_input)
image = Conv2D(16, (7,7), strides=(2,2), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = MaxPooling2D(pool_size=(2,2), strides=(2,2))(image)

image = Conv2D(48, (3,3), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = MaxPooling2D(pool_size=(2,2), strides=(2,2))(image)

image = Conv2D(32, (1,1), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = Conv2D(64, (3,3), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = Conv2D(64, (1,1), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = Conv2D(128, (3,3), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = MaxPooling2D(pool_size=(2,2), strides=(2,2))(image)

image = Conv2D(64, (1,1), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = Conv2D(128, (3,3), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = Conv2D(64, (1,1), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = Conv2D(128, (3,3), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = Conv2D(64, (1,1), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = Conv2D(128, (3,3), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = Conv2D(64, (1,1), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = Conv2D(128, (3,3), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)

image = Conv2D(128, (1,1), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = Conv2D(256, (3,3), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = MaxPooling2D(pool_size=(2,2), strides=(2,2))(image)

image = Conv2D(128, (1,1), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = Conv2D(256, (3,3), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = Conv2D(128, (1,1), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)
image = Conv2D(256, (3,3), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)

image = Conv2D(256, (3,3), strides=(1,1), activation='linear')(image)
image = LeakyReLU(alpha=0.1)(image)

out = Flatten()(image)
out = Dropout(0.20)(out)
out = Dense(100, activation='linear')(out)
out = LeakyReLU(alpha=0.1)(out)
out = Dropout(0.50)(out)
out = Dense(27, activation='linear')(out)

model = Model(img_input, out)
print(model.summary())

#model.load_weights('/home/rishab/GoogleLeNet_final_start.hdf5')
model.compile(SGD(lr=0.01, momentum=0.9, decay=0.0005, nesterov=True), loss='mean_squared_error', metrics=['accuracy'])



filepath="/home/rishab/yolo1.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

history = model.fit_generator(batches, steps_per_epoch=1242, validation_data=v_batches, validation_steps=360, epochs=10, verbose=1, callbacks=callbacks_list)

y_pred = model.predict(t_imgs,steps=1)
score = model.evaluate(t_imgs, t_labels, verbose=1)
print(score)

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'valid'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'valid'], loc='upper left')
plt.show()

K.clear_session()
