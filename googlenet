import numpy as np
import keras
from keras import backend as K
from keras.layers import GaussianNoise,GaussianDropout
from keras.models import Sequential
from keras.layers.core import Dense, Flatten
from keras.layers import Conv2D, MaxPooling2D, Activation, Concatenate, AveragePooling2D, Dropout
from keras.optimizers import Adam, SGD, Adadelta, RMSprop, Nadam
from keras.metrics import categorical_crossentropy
from keras.preprocessing.image import ImageDataGenerator
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import *
from keras.layers import Input
from keras.models import Model
import matplotlib.pyplot as plt
import cv2
from keras.callbacks import EarlyStopping, ModelCheckpoint

path = '/home/rishab/IIT_M_Internship/ASL/asl_alphabet_train'
v_path = '/home/rishab/IIT_M_Internship/ASL/asl_alphabet_valid'
t_path = '/home/rishab/IIT_M_Internship/ASL/asl_alphabet_test'

batches = ImageDataGenerator().flow_from_directory(path, target_size=(224,224), classes=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','space','T','U','V','W','X','Y','Z'], shuffle=True, batch_size=16)
v_batches = ImageDataGenerator().flow_from_directory(v_path, target_size=(224,224), classes=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','space','T','U','V','W','X','Y','Z'], shuffle=True, batch_size=16)
t_batches = ImageDataGenerator().flow_from_directory(t_path, target_size=(224,224), classes=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','space','T','U','V','W','X','Y','Z'], shuffle=True, batch_size=100)
t_imgs,t_labels = next(t_batches)

img_input = Input(shape=(224,224,3))
#image = GaussianNoise(0.5)(img_input)
image = BatchNormalization()(img_input)
image = Conv2D(32, (7,1), strides=(2,2), activation='relu')(image)
image = Conv2D(32, (1,7), strides=(2,2), activation='relu')(image)
image = MaxPooling2D(pool_size=(3,3), strides=(2,2))(image)
image = Conv2D(64, (1,1), strides=(1,1), activation='relu')(image)
image = Conv2D(192, (3,3), strides=(1,1), activation='relu')(image)
image = MaxPooling2D(pool_size=(3,3), strides=(2,2))(image)
image = BatchNormalization()(image)

#inception layer 3a
tower_3a1 = Conv2D(32, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(image)

tower_3a2 = Conv2D(48, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(image)
tower_3a2 = Conv2D(64, (3,3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_3a2)

tower_3a3 = Conv2D(8, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(image)
tower_3a3 = Conv2D(16, (5,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_3a3)
tower_3a3 = Conv2D(16, (1,5), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_3a3)

tower_3a4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same',)(image)
tower_3a4 = Conv2D(16, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_3a4)

t_3a = keras.layers.concatenate([tower_3a1,tower_3a2,tower_3a3,tower_3a4], axis = 3)
t_3a = BatchNormalization()(t_3a)

#inception layer 3b
tower_3b1 = Conv2D(64, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_3a)

tower_3b2 = Conv2D(64, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_3a)
tower_3b2 = Conv2D(96, (3,3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_3b2)

tower_3b3 = Conv2D(16, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_3a)
tower_3b3 = Conv2D(48, (5,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_3b3)
tower_3b3 = Conv2D(48, (1,5), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_3b3)

tower_3b4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(t_3a)
tower_3b4 = Conv2D(32, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_3b4)

t_3b = keras.layers.concatenate([tower_3b1,tower_3b2,tower_3b3,tower_3b4], axis = 3)
t_3b = MaxPooling2D(pool_size=(3,3), strides=(2,2))(t_3b)
t_3b = BatchNormalization()(t_3b)

#inception layer 4a
tower_4a1 = Conv2D(96, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_3b)

tower_4a2 = Conv2D(48, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_3b)
tower_4a2 = Conv2D(104, (3,3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4a2)#20

tower_4a3 = Conv2D(8, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_3b)
tower_4a3 = Conv2D(24, (5,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4a3)
tower_4a3 = Conv2D(24, (1,5), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4a3)

tower_4a4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(t_3b)
tower_4a4 = Conv2D(32, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4a4)

t_4a = keras.layers.concatenate([tower_4a1,tower_4a2,tower_4a3,tower_4a4], axis = 3)
t_4a = BatchNormalization()(t_4a)

#inception layer 4b
tower_4b1 = Conv2D(80, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4a)#25

tower_4b2 = Conv2D(56, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4a)
tower_4b2 = Conv2D(112, (3,3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4b2)

tower_4b3 = Conv2D(12, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4a)
tower_4b3 = Conv2D(32, (5,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4b3)
tower_4b3 = Conv2D(32, (1,5), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4b3)

tower_4b4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(t_4a)
tower_4b4 = Conv2D(32, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4b4)

t_4b = keras.layers.concatenate([tower_4b1,tower_4b2,tower_4b3,tower_4b4], axis = 3)
t_4b = BatchNormalization()(t_4b)

#inception layer 4c
tower_4c1 = Conv2D(64, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4b)

tower_4c2 = Conv2D(64, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4b)
tower_4c2 = Conv2D(128, (3,3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4c2)

tower_4c3 = Conv2D(12, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4b)
tower_4c3 = Conv2D(32, (5,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4c3)
tower_4c3 = Conv2D(32, (1,5), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4c3)

tower_4c4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(t_4b)
tower_4c4 = Conv2D(32, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4c4)

t_4c = keras.layers.concatenate([tower_4c1,tower_4c2,tower_4c3,tower_4c4], axis = 3)
t_4c = BatchNormalization()(t_4c)

#inception layer 4d
tower_4d1 = Conv2D(56, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4c)

tower_4d2 = Conv2D(72, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4c)
tower_4d2 = Conv2D(144, (3,3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4d2)

tower_4d3 = Conv2D(16, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4c)
tower_4d3 = Conv2D(32, (5,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4d3)
tower_4d3 = Conv2D(32, (1,5), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4d3)

tower_4d4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(t_4c)
tower_4d4 = Conv2D(32, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4d4)

t_4d = keras.layers.concatenate([tower_4d1,tower_4d2,tower_4d3,tower_4d4], axis = 3)
t_4d = BatchNormalization()(t_4d)

#inception layer 4e
tower_4e1 = Conv2D(128, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4d)

tower_4e2 = Conv2D(80, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4d)
tower_4e2 = Conv2D(160, (3,3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4e2)

tower_4e3 = Conv2D(16, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4d)
tower_4e3 = Conv2D(64, (5,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4e3)
tower_4e3 = Conv2D(64, (1,5), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4e3)

tower_4e4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(t_4d)
tower_4e4 = Conv2D(64, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_4e4)

t_4e = keras.layers.concatenate([tower_4e1,tower_4e2,tower_4e3,tower_4e4], axis = 3)
t_4e = BatchNormalization()(t_4e)
t_4e = MaxPooling2D(pool_size=(3,3), strides=(2,2))(t_4e)

#inception layer 5a
tower_5a1 = Conv2D(128, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4e)

tower_5a2 = Conv2D(80, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4e)
tower_5a2 = Conv2D(160, (3,3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_5a2)

tower_5a3 = Conv2D(16, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_4e)
tower_5a3 = Conv2D(64, (5,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_5a3)
tower_5a3 = Conv2D(64, (1,5), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_5a3)

tower_5a4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(t_4e)
tower_5a4 = Conv2D(64, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_5a4)

t_5a = keras.layers.concatenate([tower_5a1,tower_5a2,tower_5a3,tower_5a4], axis = 3)
t_5a = BatchNormalization()(t_5a)

#inception layer 4e
tower_5b1 = Conv2D(192, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_5a)

tower_5b2 = Conv2D(96, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_5a)
tower_5b2 = Conv2D(192, (3,3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_5b2)

tower_5b3 = Conv2D(24, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(t_5a)
tower_5b3 = Conv2D(64, (5,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_5b3)
tower_5b3 = Conv2D(64, (1,5), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_5b3)

tower_5b4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(t_5a)
tower_5b4 = Conv2D(64, (1,1), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0035))(tower_5b4)

t_5b = keras.layers.concatenate([tower_5b1,tower_5b2,tower_5b3,tower_5b4], axis = 3)
t_5b = BatchNormalization()(t_5b)
t_5b = AveragePooling2D(pool_size=(2,2))(t_5b)

out = Flatten()(t_5b)
out = Dropout(0.35)(out)
out = Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.01))(out)
out = Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01))(out)
out = Dense(27, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(out)

model = Model(img_input, out)
print(model.summary())
#model.load_weights('/home/rishab/GoogleLeNet_final_start.hdf5')
"""
model.compile(Adam(lr=0.0075), loss='categorical_crossentropy', metrics=['accuracy'])



filepath="/home/rishab/GoogleLeNet_final_start.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

history = model.fit_generator(batches, steps_per_epoch=4967, validation_data=v_batches, validation_steps=1437, epochs=10, verbose=1, callbacks=callbacks_list)

y_pred = model.predict(t_imgs,steps=1)
score = model.evaluate(t_imgs, t_labels, verbose=1)
print(score)

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'valid'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'valid'], loc='upper left')
plt.show()
"""
K.clear_session()
